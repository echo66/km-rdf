\documentclass[runningheads]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\usepackage{url}
\urldef{\mails}\path|{david.pastor, yves.raimond, samer.abdallah, mark.sandler}@elec.qmul.ac.uk|

\begin{document}

\mainmatter

\title{A Logic-Based Framework for Digital Signal Processing}

\titlerunning{A Logic-Based Framework for Digital Signal Processing}

\author{David Pastor\and Yves Raimond\and Samer Abdallah\and Mark Sandler}

\institute{Centre for Digital Music, Queen Mary, University of London,\\
\mails}

\maketitle


\begin{abstract}
In this paper we describe a logic-based framework for Digital Signal Processing (DSP). This framework is implemented as a set of SWI-Prolog modules developing interfaces to heterogeneous signal processing libraries. Prolog terms representing common datatypes and a standard format for binary data are used to mediate between the different components of the system. The system provides the user with a unified and flexible front-end to define signal processing workflows. Using this framework, we develop a signal processing-enabled reasoner capable of performing the primary tasks through the following interfaces: decoding (specific libraries for each format), feature extraction (Vamp plugins), audio processing and effects (LV2/LADSPA plugins) and classification (WEKA machine learning API).

\keywords{Digital Signal Processing, SWI-Prolog modules, signal processing workflows, processing-enabled reasoner, interfaced open source engines}
\end{abstract}

\section{Introduction}\label{sec:intro}
Digital signal processing (DSP) is a broad field and an important object of engineering research. Within this research community, particular investigators are discovering and developing new algorithms for signal processing and analysis. Many projects aim at developing formal APIs providing a framework for algorithms implementation. However, these APIs are normally designed as a closed environment which hardly interacts with other related APIs and applications. Although several APIs are wrapped and exported as ``plugin'' libraries which can be embedded in different applications, they still require the implementation of specific and non-interactive hosts.

This situation leads to many isolated applications, environments and sources of data working independently from each other. Any effort to combine them to obtain integrated results for analysis, classification and comparison requires tedious studies or ``glue code'' implementations.

In this paper we address this problematic situation by proposing and developing SWI-DSP, a logic-based framework for \textit{Audio Processing} (as subset of DSP) built on a predicate calculus implementation: SWI-Prolog \cite{swi}. We rely on a logic programming language with foreign language modules providing audio analysis capabilities to get rid of the application-dependency paradigm and offering a single logic-based front-end. Logic resources are also used to achieve a more capable DSP engine: a signal processing-enabled reasoner. The main and primary motivation for a logic-based implementation of such a system is to turn our conception of traditional procedural applications for computation of data towards declarative semantic frameworks to manage knowledge involving specific computations.

In \S 2 we identify the most common audio analysis tasks and summarise several relevant open source APIs aimed at performing such tasks. We evaluate the advantages and limitations of these APIs in order to find the requirements for SWI-DSP. In \S 3 we start viewing the system from the top and how it defines an interesting workflow-based architecture that characterises input/output relationships between processing tasks. These workflows are possible by means of common datatypes and a binary data standard format. \S 4 goes into the implementation of the modules that develop a communication layer with dedicated audio processing libraries.

Thus, SWI-DSP develops predicates triggering external computation performed by dedicated APIs. The datatypes allow and constrain the predicates communication and instantiation. These predicates are organised into modules with different levels of abstraction. However, this architecture lacks of an uniform interface to create programs suitable for the concrete needs. We tackle this problem in \S 5 by defining an unified and flexible front-end, composed by DSP ``scenarios'', which allows the user to define workflows with understandable semantics.

Data management is an important paradigm involved in many domains and also in the multimedia research domain. Computations can not often be retrieved from session to session or are stored in local filesystems. Local data repositories are unlikely directed to extend any shareable source of knowledge because they are not expressed in a standard format with common semantics.

Although SWI-DSP does not develop a data management system itself, we discuss this problem in \S 6 and present related works which contribute to achieve such a multimedia knowledge reasoner/manager. We conclude in \S 7 by assessing the value and scope of this work and introducing future advances.

\section{Audio processing tasks and solutions}\label{sec:tasks}

A particular application of DSP is the study of audio signals: one-dimensional, time domain signals, however, they also have representations in other domains such as frequency, time-frequency, etc. Audio signals evolve in time and have acoustic properties produced by the signal structure and shape. Music and speech are the main fields involving audio signals.

The properties of an analog and continuous signal (acoustic signals) can be studied by analysing their digital (sampled and quantised) versions. A one-dimension digital signal is therefore a mapping from a discrete time domain (usually finite) to a discrete value domain and is often represented as a sequence of values associated with successive time points. Digital signals can be processed to make new derived signals or extract some of their characteristics.

We consider the following digital signal processing tasks.

\begin{itemize}
 \item Effects;
 \item Feature Extraction;
 \item Classification.
\end{itemize}

\subsection{Effects}\label{subsec:effects}
A first step in many signal processing is a normalisation, conditioning or re-representation of the signal, which may involve several techniques such as filtering, amplification, Fourier transforming, etc.

It is very common in musical systems to provide tools that modify acoustic properties of the signal by introducing specific effects. Reverberation, delay or distortion are examples of effects that can be digitally obtained reproducing natural or instrumental alterations of the signal.

In practise, we characterise this group of tasks by its input/output relationships. The operation outputs a signal (which may be time, frequency or multidimensional domain) when it is fed with an input signal. Oscillators and synthesis systems outputs signals without any inputs.

One important dedicated API is the Linux Audio Developer's Simple Plugin API (LADSPA) \cite{ladspa}  which has been successfully used in many systems and applications and is a widely spread implementation for algorithms development. We host LADSPA in SWI-DSP but there are other interesting libraries like DSSI plugins for effects and LV2 (new generation of LADSPA) which are targets for future extensions.

\subsection{Feature Extraction}\label{subsec:feature}

Acoustic properties which are the substrate of the psychological perspective of audio signals are conveyed in the signal and therefore in their digital representations. The so-called feature extraction paradigm aims at extracting different levels of audio features to characterise, classify and compare the audio signals (and any signal in general). The domain of the feature represents a qualitative facet of the signal (tempo, chromatics, timbre...), so features do not convey all the signal information. This is interesting as distinct signals may have some very close features and differ significantly in others.

The Vamp Plugins API \cite{vamp} offers a framework to develop feature extraction plugins that can be hosted in any application able to control the ``plugin lifecycle''. We host Vamp plugins as basis for feature extraction in SWI-DSP. In general, plugin libraries are characterised for being suitable for development but application-dependent.

\subsection{Integrative solutions}\label{subsec:inte}

With the same motivation of this work there are some integrative APIs which combines different tasks to perform low and high-level operations in a closed implementation. CLAM \cite{clam}, jMIR \cite{jmir} and Marsyas \cite{marsyas} present a complex framework collecting tools to perform different DSP tasks. The most interesting feature of these frameworks is the possibility to create DSP networks combining specific algorithms and modules thanks to a workflow-based architecture (Marsyas and CLAM) or with a descriptive data format (jMIR).

CLAM also offers a metamodel of DSP processes which provides semantics to design the networks properly presenting a higher and more manageable level of abstraction. However, these APIs still present two important limitations that our work is aimed at solving:

\begin{itemize}
 \item They do not offer a common format to exchange data or an easy way to interact with other applications;
 \item They are based on a procedural system unable to collect and integrate knowledge from different sources to obtain new knowledge.
\end{itemize}

\subsection{Classification}\label{subsec:classif}

Classification is one the most interesting and complex paradigms in any specific domain exploiting the ``intelligence'' of computational machines. WEKA (Waikato Environment for Knowledge Analysis) \cite{weka} collects different machine-learning algorithms and provides several user interfaces to manage the analysis. It also provides a formal interface (in Java) for development and interaction with other systems.

However, this generic API does not provide semantics to create a dataset which is the most intriguing and complex issue for classifying data properly. Marsyas and jMIR integrate WEKA orienting it for music classification purposes by offering a code interface with other modules (Marsyas) or by extending the WEKA file format ARFF (jMIR). Both solutions still seem to lack of effective semantics and a interactive front-end to perform classification of audio data.

\section{SWI-DSP architecture}\label{sec:architecture}

From the previous comparison and review we consider the following requirements:

\begin{itemize}
 \item Allowing workflow design;
 \item Providing an interface to interact with other related systems and applications;
 \item Featuring an unified, flexible, interactive and understandable front-end;
 \item Providing an open-development platform;
 \item Management of shareable data semantically labelled;
 \item Enhancing traditional procedural implementations by building a logic-based framework of declarative nature allowing reasoning and inferring.
\end{itemize}

As initial step, we build a framework able to develop digital signal processing workflows based on a predicate logic implementation (SWI-Prolog) extending its vocabulary by wrapping computations under logic predicates. We develop task-oriented modules and define functors capturing the common datatypes allowing the communication between modules and hiding the internal implementation. In addition to this, we define a standard format for binary data exchanged among processing modules. We define these utils in the \textbf{swilib} module which provides a C++ library and a SWI-Prolog module for their management.

Processing libraries and analysis applications are normally implemented in fast and efficient code using an imperative language (e.g. C/C++) which is machine-operation oriented instead of focused on task knowledge. Functional programming offers a different paradigm. Functional languages try to capture the meaning of computational tasks in a more declarative way, using functional relationships to describe ``what'' the computation should be rather than ``how'' to do it. Modern functional languages like Haskell \cite{haskell} provide rich and powerful type systems describing and constraining the set of legal values a function can take as input or return as output. This seems to be a better approach to define high-level audio processing functions, but C/C++ is still the language for the most important open source resources.

Logic programming languages have also a high-level and declarative nature. They combine knowledge and rules to reason about the knowledge and infer new insights. This is an important feature to consider a logic framework as underlying mechanism to relate the hierarchy of data involved in multimedia domains. However, they are not as powerful as a computational machine even when it is possible to declare procedures with an execution sequence. There are several works that develop a typed-functional language on a logic framework like lambda-Prolog or Mercury \cite{mercury}. Mercury embeds computational capabilities in a purely declarative language within a strong typed and moded logic framework. Mercury types and predicate modes provide the compiler with the information to generate efficient code but as environment for declaring and interactive prototype, Mercury is ``less forgiving'' than Prolog. SWI-Prolog in particular has a very comfortable development environment and hence we use SWI-Prolog.

Our approach results to be more suitable to develop an open platform for research and development. External engines based on open source APIs provide faster computations than any functional or logic/strong-typed language and a suitable developers interface.

\subsection{Datatypes controlling workflows}\label{subsec:datatypes}

In section \ref{sec:tasks} we have seen how tasks are strongly characterised by their input/output relationship. The system requires datatypes that guarantee the correct input and output matching. We identify these datatypes by analysing the tasks classification. We also want to look at the Music Ontology specification \cite{mo} as a formal description of music-related concepts including audio analysis terminology. We distinguish the following datatypes to any signal processing system:

\begin{itemize}
 \item signal: this type represents an audio signal in a physical timeline;
 \item feature: this type represents some facet of the audio signal properties;
 \item parameter: this type represents the different variables of the computation context (computations are not only a one-to-one function);
 \item timestamp: this type represent the reference of a data object to a timeline.
\end{itemize}

We implement these datatypes in SWI-Prolog as functors (name/arity) that bind together the attributes of a concept (e.g. signal(Channels, SampleRate, Length, [DataIdPerChannel])). These datatypes (with the disadvantage of being a non-flexible model) can be interpreted by any module guaranteeing the correct instantiation pattern of the predicates and ensuring a valid execution.

\subsection{Large Binary Objects}\label{subsec:blobs}

Large binary data is present in any multimedia system and needs to be treated in the most efficient and manageable way. The so-called BLOBs are objects wrapping large binary data. The representation of data in SWI-Prolog can be done through lists which can not handle such amount of data (e.g. signals of 1000000 samples) or through SWI-Prolog BLOB terms which are cumbersome as datatype.

We have implemented a mechanism of unique \textit{data identifiers} that are stored in a structure updated at runtime. Each identifier holds the binary representation of an arbitrary large sequence of floating point format data. This identifiers-based system is useful in the following ways:

\begin{itemize}
 \item It hides the raw binary representations or inefficient SWI-Prolog lists by handy representations of data as atoms: e.g. \textbf{\_\_data\_435};
 \item It implements a look-up database whose status can be easily updated and checked;
 \item It provides multiple ways to export/import data from the structure through the identifiers. Data can be wrapped into or extracted from a blob term and displayed/read as Prolog list (length restrictions). It allows dumping data into or loading it from a binary file (using the identifiers to keep track of the data);
 \item It unifies the ``raw'' data representation allowing the communication at the lowest level between modules;
 \item One identifier can be used to retrieve data from a previous session as long as we make the data object persist under its identifier and reserve the identifier in the new session.
\end{itemize}

The following example shows how a decoded audio file can be easily represented by the data identifiers that make easy to work with such a big sequence of data. A data identifier can be used in the same way as the name of a person to identify a data object which is related to other entities within a predicate.
\begin{verbatim}
?-decode('../myfile.*', Signal).
Signal = signal(2, 44100, 1200000, ['__data_0', '__data_1']).

%we can relieve memory by dumping the data into files 
%and loading it later on. Files will have the corresponding id
?-data_out('__data_0').
?-data_out('__data_1').

?-data_in('__data_0'), data_in('__data_1'),
get_frame(signal(2, 44100, 1200000, ['__data_0', '__data_1']), 200, 5,
frame(Ch, Sr, L, [Ch1D, Ch2D])),
data_to_list(Ch1D, List), length(List, Llen).
Ch1D = '__data_2'
List = [6.45, 4.56, 3.23, 9.78, 3.26]
Llen = 5
\end{verbatim}

\subsection{Processing workflows}\label{subsec:worflow}

\begin{figure}
\centerline{\framebox{\includegraphics[width=\columnwidth]{workflow.png}}}
\caption{Example of how to create a workflow: extract the tempo of a signal and a reverberated version of it}
\label{fig:workflow}
\end{figure}

Figure \ref{fig:workflow} shows a possible workflow that is designed by using the functional framework formed of datatypes, a standard format for data and the modules of SWI-Prolog predicates which are described in \ref{sec:modules}.

\section{SWI-DSP modules}\label{sec:modules}

Each task module (functional predicates) is composed by lower level modules which offer communication with an external API or library in charge of the computations. By hosting ``plugin libraries'' we can extend easily the SWI-DSP vocabulary (new plugins can be added without code modifications). These low level modules are not constrained by datatypes (every API deals with its own concepts) so they require a precise understanding of the API and the interface.

\subsection{swiaudio}\label{subsec:swiaudio}

This module is in charge of providing audio data to the system. This module is splitted in two sub-modules: \textbf{swiaudiosource} and \textbf{swiaudiodata}. The former is a module for decoding which interacts with C decoding libraries (mad, soundfile, fishsound, oggz and faad) to extract a \textit{Signal} term given and audio input file supported by the libraries. This process is triggered by a simple call to the predicate \textit{aspl\_decode(+InputFile, -Signal)} which recognises the file extension and calls a specific library allowing a fast decoding process and even more important an independent term representing the encoded data in a standard way for the supported formats: mp3, ogg, mp4, aac and wav.

The latter is a module which defines utilities typically required in DSP. The most important set of predicates is dedicated to framing. The rest of predicates are mainly oriented to extract information from a Signal or a Frame term.

\subsection{feature extraction}\label{subsec:swivamp}

This module defines a set of predicates and rules (specific API routines for the computations) for feature extraction. As we have seen in \S 2, the module is characterised for a clear input/output relationship. So we can declare a simple predicate to extract the tempo of an audio signal: tempo(+Input, -Tempo) being Input an instantiation of the Signal datatype and Tempo a list of instantiations of the Feature datatype. This predicate, that returns a tempo-related list of features given an input signal, is indeed triggering a specific computation tool, so we could select the specific tool by extending the predicate: \textit{tempo(+Input, +Tool, -Tempo)}.

We rely on the Vamp Plugin API as it offers an efficient plugin and host implementation. Certainly, there is a limitation in the sense that any feature extraction algorithm we may want to use has to be implemented as Vamp Plugin. As a counterpart, it is easier to write an algorithm as Vamp Plugin than to interface many APIs or particular algorithm implementations.

The sub-module \textbf{swivamp} is a communication layer based on the SWI-Prolog foreign interface allowing us to query the plugin information, set up the plugin context for the transform, execute the plugin given a Signal term and retrieve the output features for the plugin according to the lifecycle specification. Plugins are wrapped in a similar fashion than the audio data so we can use a plugin instance representation (a plugin id pointing to a plugin instance existing in memory), so that we can have concurrent plugins working at the same time. The previous tempo/3 predicate is declared as this set of rules (defined with a procedural meaning):

\medskip
\noindent
\begin{verbatim}
tempo(Input, Tool, [feature(Type, Timestamp, Feature)|...]):-
     Input = 'Signal'(Ch, Sr, L, PCMs),
     Tool = 'Vamp',
     vamp_feature_of(tempo, Input, Tempo).

vamp_feature_of(Type, Signal, WholeFeature):-
     select_plugin(Type, PluginKey, Output),
     vamp_outputs_for(Signal, PluginKey, Output, Features),
     flatten(Features, WholeFeature).

vamp_outputs_for(Signal, PluginKey, Output, Feature):-
     vmpl_load_plugin_for(PluginKey, Signal, Plugin),
     set_blockSize(Plugin, Block),
     set_stepSize(Plugin, Step),
     get_channels(Signal, Channels),
     vmpl_initialize_plugin(Plugin, Channels, StepSize, BlockSize),
     vamp_compute_feature(Signal, Step, Block, Outputs, Plugin, WholeFeature).

vamp_compute_feature(Signal, Step, Block, Outputs, Plugin, Features):-
     get_samples_per_channel(Signal, L),
     findall(F, vamp_process_signal(Signal, L, Step, Block, Output, Plugin, F), FSet),
     get_sample_rate(Signal, SampleRate),
     vmpl_remaining_features(Plugin, L, SampleRate, Outputs, Remaining),
     append(FSet, Remaining, RawFeatures),
     delete(RawFeatures, [], Features).

vamp_process_signal(Signal, L, StepSize, Block, Out, Plugin, Features):-
     set_limit_framing(L, StepSize, Limit),
     set_framing(StepSize, L, Limit, Start),
     vmpl_process_block_framing(Plugin, Signal, Start, Block, Out, Features).

\end{verbatim}
\noindent

The first rule selects the tool for the queried feature. The following one identifies automatically the specific plugin within the Vamp API in charge of extraction the ``tempo'' (and passes a term to unify the returned feature). The third predicate sets up the plugin for the processing (in this case with default parameters). The predicate vamp\_compute\_features acts as host retrieving and organising the extracted features which are indeed computed by the last predicate. This last predicate configures the framing and calls the swivamp interface that rapidly communicates and executes the plugin (the efficiency of the extraction is preserved). The features are returned as a list of terms represented using the feature datatype: feature(type, timestamp(start, duration), '\_\_data\_id').

\subsection{audio processing}\label{subsec:swilasdpa}

This module defines any computation which outputs a Signal term. It comprises any sort of effect or filtering over a signal. It reproduces a real time processing by outputting processed frames as they are computed (non-deterministic call to a processing predicate) or stores the processed blocks to return and altered version of the input signal.

The module swiladspa offers communication with LADSPA which is the most generic and spread plugin API for general audio processing. The communication layer allows us to query the plugin description, control the set up of the plugin (control and audio ports) and retrieve the processed data. Through predefined routines we can offer a more handy access to the plugin or even declared predicates just defined by an input/output relationship.

\subsection{swiweka}\label{subsec:swiweka}

The WEKA API is interfaced through the package JPL available for SWI-Prolog defining a complex Java-Prolog interface to read/write ARFF files, load ARFF files, instantiate classifiers, execute classification and retrieve the classification scores of the dataset. This communication layer offers by itself a really cumbersome and API-dependent module. It requires semantics and interpretation rules to become into a useful logic-framework for audio data classification as described in the next section.

\section{DSP front-end}\label{sec:frontend}

So far we have presented how SWI-DSP provides a vocabulary of logic predicates and datatypes to perform audio analysis imitating a functional language, but this approach is still inappropriate for such tasks. We have organised the modules in communication layers and task-oriented modules, but there is an important trade-off between understandability and specification. The communication layer even offering an application-independent access to the computation libraries still requires a high knowledge of such libraries besides a SWI-Prolog familiarisation. However, these requirements are not expected in most part of the potential users. The datatypes are not the only necessary semantic resource to provide an actual workbench for DSP. We require a front-end that reflects the experimental domain providing an interactive ``laboratory''.

We define some ``DSP scenarios'' that reflect the researching activity. This scenarios define the necessary patterns and datatypes (implemented as predicates and functors) to allow the user to actually perform high-level research preserving the necessary flexibility. The elementary scenarios are:

\begin{itemize}
 \item Transform: This scenario provides a pattern to apply any computation over an audio signal. It specifies by a datatype the framing parameters, the running engine, the engine configuration and parameters, the sample rate (if variable), the type of transform and the domain specifications. These factors are captured with a functor used to link input/output (with full flexibility) in transform(+Input, +Transform, -Output)
 \item Classification: This scenario is provided for a proper setup of classification. This scenario specifies the classification domain, the categories (names, types and ranges), the classification schema and the training set. It also provides a pattern for the input data set which is interpreted along with the classification environment to return the output distribution.
\end{itemize}

The patterns and functors are interpreted by hardcoded prior knowledge which starts up the subsequent steps to provide the queried output. More complex scenarios can be created in order to achieve higher or broader semantics for research activity.

This logic-based framework for DSP (Fig. \ref{fig:dspdrawing}) develops an interactive computational engine that exploits logic resources and their declarative nature (but still using procedural meaning). Such an engine can be embedded in other environments (by SWI-Prolog interfaces to other languages) developing graphical interfaces, visualisation applications or data management systems. In section \ref{sec:datamanage}, we introduce the elements to attain a declarative framework to reason about computations and processed data (which requires a management system).

\begin{figure}
\centerline{\framebox{\includegraphics[width=\columnwidth]{swidsp.png}}}
\caption{Arquitecture of SWI-DSP}
\label{fig:dspdrawing}
\end{figure}

\section{Data management and computation reasoning}\label{sec:datamanage}

We still need to address, probably, the most important issue to accomplish the proposed architecture. We could say that such a system is indeed aimed at managing complex and large data, which is related through functional ``blocks'', and allowing reasoning about it. This goal requires the following capabilities: an efficient storage of data objects and the relationships (predicates) linking them, mechanisms to control the concurrency, consistency and side-effects of the computations and a high-level interface to interact with them.

We do not develop such manager within SWI-DSP, but we describe a Prolog-based framework that provide these services and to which SWI-DSP can provide computational services. Functional predicates can be externally stored in a database as tabled predicates. Those predicates can be seen as a \textit{relation} and each \textit{record} is formed of the terms of a particular instantiation of that predicate. By tabling functional predicates we can avoid re-computations of the same predicate treating it as another ``fact of the world''.

This database is seen from a deductive model (facts and rules in prolog), so inferences over relational knowledge are also allowed. For this purpose, the data identifiers mechanism seems to be ideal as data ids are relationally linked and stored wrapping complex data as units of knowledge. The data objects referred by the ids are made persistent between sessions by dumping the data to an external file which can be retrieved through the data identifier (directly or through a mapping). The data object is loaded at runtime any time we use a query involving a fact referring to its identifier.

This data management framework described as in \cite{aes2006} can be extended by handling transaction logic constructs. Transaction logic provides the formalism to combine, with a declarative meaning, functional predicates and actions that read or change the ``state of the world'', such as database updates, creation of files on disk or interaction with a user.

\subsection{Transaction Logic}\label{subsec:ctl}

Transaction Logic \cite{ctl}  unifies in a declarative formalism the control of an underlying database (SWI-Prolog and other prolog implementations just rely on assert and retract predicates for data updating, being very limited). Transaction Logic allows a declarative definition of execution paths and database updates by providing new connectives to express complex data transactions: parallel and serial conjunctions, execution in isolation and executability checking. Rules define possible execution paths for a goal with a higher-level meaning than just declared procedures. Thus, we are certainly dealing with actions (and their effects) instead of sequences of predicates.

We can manage the side effects of computation on an underlying database in a consistent way, reason about the actions and their effects, control the execution of different processes and compare different paths for the same goal. Transaction logic applied to complex data/computational environments has been successfully applied to develop ``virtual laboratory workbenches'' \cite{virtual}. 

SWI-DSP combined with a database manager based on Concurrent Transaction Logic (CTR), which also controls concurrent processes, develops a multimedia knowledge system to drive research with semantics and a logic formalism exploiting reasoning and declarative definition of computations and providing an interactive source of knowledge.

\subsection{Implementation}

\begin{figure}
\centerline{\framebox{\includegraphics[width=\columnwidth]{reasoner.png}}}
\caption{Collaboration diagram between SWI-DSP, the Matlab interface and the reasoner implementations}
\label{fig:reasoners}
\end{figure}


%Samer's KM and Henry...



% FIXME - Hmm... Not good in the current state.
%\subsection{Henry}\label{subsec:henry}
%We present a related project so-called Henry which develops a real CTR-based agent aimed at creating a distributed multimedia knowledge workspace built on semantic web technologies. The multimedia community needs a standard machine-readable format with proper semantics to manage complex data involved in any sub-domain, so data can be exchanged and shared by different systems enriching the common knowledge.

%The Resource Description Framework (RDF) developed as the standard format for new (data-oriented) web technologies expresses linked data by means of triples in the form of (Subject, Predicate, Object). This standard can be implemented with different syntaxes. We prefer Notation3 \cite{n3} whose syntax allow us to write RDF statements in a human-readable way and also to write ``rules'' as named graphs. The Ontology Web Language (OWL) provides the framework to express the knowledge of a particular domain in RDF through concepts and relationships. Thus, descripting semantic models related to audio analysis are not restricted to a local implementation but can be shared and processed by different systems. These elements form a suitable framework to represent and manage data and algorithms in a ``web of (complex) data''.

%Henry develops an N3/Prolog parser and reasoner based on CTL. (Text for Yves). Talk about results and performance...
%(talk about data visualisation?)

\section{Conclusion and Future work}\label{sec:conclusion}

(may have to reword this after all the changes)
We have presented a powerful reasoner for multimedia analysis implemented as a logic-based framework which allow us to convert low-level computations into shareable and distributed knowledge. The system design ``breaks apart'' traditional applications architecture to introduce logic and reasoning machinery on top of the computation engines providing a more intelligent, capable and understandable DSP reasoner. This reasoner can be extended and enriched by the open source APIs working on the foundations of the system and controlled by ''Prolog-speaking`` agents. SWI-DSP is fairly well positioned for the new web technologies and actually it finds in them the perfect semantic and storing support to overwhelm traditional and closed DSP systems.

Future work and development is oriented to:

\begin{itemize}
 \item Testing and comparison of performance with other rival systems
 \item Extending the SWI-DSP vocabulary and capabilities
\end{itemize}

SWI-DSP vocabulary and capabilities can be extended in several ways. First, by interfacing more open source APIs to cover the implementation of any DSP task (not necessarily restricted to audio domain). Secondly, by supporting symbolic data (MIDI) input which is a really important source of audio knowledge and providing analysis modules for such an input. Finally, other logic paradigms can contribute to enhance SWI-DSP (e.g. there are studies that use Inductive Logic Programming systems to extract harmonic rules or rhythm patterns given certain input descriptors [ref]). By providing semantics (OWL ontologies clearly point to this goal) to interconnect properly each logical module we can build a hierarchy of modules which help us to extract and share different levels of knowledge from digital signals. Such a system could be used either to extract low level cepstral coefficients from an input signal (mathematics level) or to obtain patterns of music (musicology level).

\begin{thebibliography}{4}

\bibitem{distributed} Raimond, Y., Sutton, C., Sandler, M.: A distributed data space for music-related information. In: Workshop on the Many Faces of Multimedia Semantic. ACM (Multimedia), Augsburg (2007).

\bibitem{ctl} Bonner, A.J., Kifer, M.: Concurrency and Communication in Transaction Logic. In: Joint International Conference and Symposium on Logic Programming, pp. 142--156. Bonn (1996)

\bibitem{tlprog} Bonner, A.J., Kifer, M.: Transaction Logic Programming. In: 10th International Conference on Logic Programming. Budapest (1993)

\bibitem{virtual} Bonner, A.J., Shrufi, A., Rozen, S.: LabFlow-1: a Database Benchmark for High-Throughput Workflow Management. In: 5th International Conference on Extending Database Technology, pp. 463-478. Springer-Verlag, Lecture Notes in Computer Science, volume 1057. Avignon (1996).

\bibitem{aes2006} Abdallah, S., Raimond, Y., Sandler, M.: An ontology-based approach to information management for music analysis systems. In: 120th Audio Engineering Society. Paris (2006).

\bibitem{clam} CLAM, \url{http://www.clam.iua.upf.edu/}

\bibitem{marsyas} Music Analysis, Retrieval and Synthesis for Audio Signals. \url{http://marsyas.sness.net/}

\bibitem{jmir} McKay, C.: jMIR. \url{http://jmir.sourceforge.net/}

\bibitem{mo} Raimond, Y., Abdallah, S., Sandler, M., Frederick, G.: The Music Ontology. In: 8th International Conference of Music Information Retrieval. Vienna (2007)

\bibitem{kmrdf} Source code project of KM-RDF. \url{http://code.google.com/p/km-rdf/w/list}

\bibitem{ladspa} Linux Audio Developer Simple Plugin API. \url{http://www.ladspa.org/}

\bibitem{vamp} Cannam, C.: Vamp Plugins. \url{http://www.vamp-plugins.org/}

\bibitem{weka} WEKA home site \url{http://www.cs.waikato.ac.nz/ml/weka/}

\bibitem{mercury} Mercury Home Project \url{http://www.cs.mu.oz.au/research/mercury/index.html}

\bibitem{haskell} Haskell \url{http://www.haskell.org/}

\bibitem{swi} SWI-Prolog Home \url{http://www.swi-prolog.org/}

\bibitem{n3} Notation3 \url{http://www.w3.org/DesignIssues/Notation3}

\end{thebibliography}

\end{document}
